{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1kdJWj_-vY0dKG2g1n_ntNVRlf1mdWHtd","authorship_tag":"ABX9TyOJiOpEj/9O2uiBDsjlkzOE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Here is my assignment \n","\n","Name: Manish H T \n","\n","Roll No.: 21D1700024\n","\n","Note: \n","1. The questions are not in a particular order, I have started with the easier once first.\n","2. I have taken help from my group members and my classmates \n","   Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra \n","3. I have helped the above named people and as well as Harshit Meena\n","4. For most of my doubts I have used https://stackoverflow.com/, https://www.kaggle.com/,https://www.w3schools.com/datascience/ . I loved the way of explaination in stackoverflow, the contents of W3School was well organised\n"],"metadata":{"id":"4J4pvRE9V9zf"}},{"cell_type":"markdown","source":["\n","2nd Question\n","I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena\n","\n","2.)For this question the joint probability function is simply given by multiplying the individual function because both function are independent. The Function is given by F(g,a)=ag/(45*45) if a,g belongs to [0,45] else equal to 0. The expression is divided by 45squared because the integration from -infinity to +infinity should be 1 whch can be accomplished by the term. (b)IN order to have the lunch together it should satisfy |f-g|<10, since both of them will not wait for more than two minutes.Also f and g are defined only in [0,45]. To get the answer of the question graphical method can be (The image:https://drive.google.com/file/d/1vUQIxG2weSTIUza8seoXLypBD1MsSsZl/view?usp=share_link) Here the probability will be equal to Area of black shaded part divided by whole area of the square=1-(35^2)/(45^2)=0.395 (c)Pic link:(https://drive.google.com/file/d/1sTABviGKC-klMM4pQVfP5dzE0O8N2dz5/view?usp=share_link) Here the answer will be intersection of both area divided by area of the square=0.148"],"metadata":{"id":"5K3fpp9Pn71w"}},{"cell_type":"markdown","source":[],"metadata":{"id":"NvpPi3mEoF_z"}},{"cell_type":"markdown","source":["3. Probability distribution (10 marks) Our low-density lipoprotein (LDL) cholesterol reading is indicative of the risk of heart disease. You can take the mean for the LDL of our city’s adult population as µ = 90mg/dl and that 65% of the population have a LDL less than 110 mg/dl. Let’s assume that LDL is normally distributed and use X to represent the reading in mg/dl.\n","\n","(a) Determine the standard deviation (σ) for X.\n","\n","(b) Which quantile of people can be considered healthier?\n","\n","(c) What is the LDL value that is exceeded by 95% of the population?\n","\n","(d) If the normal range is LDL below µ + σ. What is the corresponding bound fornormal LDL values? Round off your answer to the nearest integer value.\n","(e) An adult has a moderate risk of heart disease if their LDL is between µ + σ and µ + 2σ. What fraction of the population is at moderate risk?\n","\n","(f) Use scipy.stats to generate a sample of 10,000 people from our city. Plot the histogram and a horizontal boxplot for this sample, one above the other. Compute and print the sample mean and standard deviation on one of these plots.\n","\n","(g) Note your observations for the plots above. Do you notice anything odd about the distribution of LDL\n","\n","I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena"],"metadata":{"id":"72-VrWH8oGs-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjtwvQkq4lw7"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as st\n","import matplotlib.pyplot as plt\n","mean = 90\n","z_value = stats.norm.ppf(0.65)\n","std = (110 - mean)/z_value\n","print(\"Standard deviation of the given instrument is \", round(std,3))"]},{"cell_type":"code","source":["# Answer to Part (b)\n","z_value1 = (100 - mean)/std\n","Quantile = stats.norm.cdf(z_value1)\n","print(\"Quantile of people that can be conisdered healthier is\", round(Quantile,3))"],"metadata":{"id":"tt63zysxUBt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer to Part (c)\n","\n","#Fraction of population below the required value of LDL = 1 - 0.95 = 0.05\n","z_value2 = stats.norm.ppf(0.05)\n","Number = (std * z_value2) + 90\n","print(\"LDL value exceeded by 95% of the population is\", round(Number,3))"],"metadata":{"id":"Dg7XpYQqUMGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer to Part (d)\n","\n","Lower_bound = 0\n","Upper_bound = mean + std\n","print(\"The bounds corresponding to the normal LDL values is (\", Lower_bound, \",\", round(Upper_bound,0), \")\")"],"metadata":{"id":"abVuWkVwUQ_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer to Part (e)\n","\n","# For x = mean + standard_deviation, z_value = 1\n","# For x = mean + 2* standard_deviation, z_value = 2\n","# Thus, required fraction = (value corresponding to z_value = 2) - (value corresponding to z_value = 1)\n","ModerateRisk = stats.norm.cdf(2) - stats.norm.cdf(1)\n","print(\"Fraction of population at moderate risk is \", round(ModerateRisk,3))"],"metadata":{"id":"NxAhh4dKUWtq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer to Part (f)\n","# Create a standard normal distribution with mean as 90 and standard deviation as std\n","snd = stats.norm(mean, std)                                                        # Generate 10000 random values between 0 and 180 \n","x = np.linspace(0, 180, 10000)                                                     # Plot the standard normal distribution for different values of random variable falling in the range 0, 180\n","\n","plt.figure(figsize=(7.5,7.5))\n","plt.plot(x, snd.pdf(x))\n","plt.xlim(0, 180)\n","plt.title('Normal Distribution', fontsize='15')\n","plt.xlabel('Values of Random Variable X', fontsize='15')\n","plt.ylabel('Probability', fontsize='15')\n","plt.show()"],"metadata":{"id":"MC3aIyNeUjIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer to Part (g)\n","# Reference : https://stackoverflow.com/questions/20864847/probability-to-z-score-and-vice-versa"],"metadata":{"id":"33tCPTwmU-r7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena\n","\n","1. Sampling distribution (5 marks)\n","\n","Use the beta distribution with a = 2, b = 5 in scipy.stats to generate a sample\n","size of n = 5000, and call it X. When generating the random numbers using rvs, use\n","random state = g where g is your group or team number. You may use any code that I\n","have given you during the course and modify it for your use. For help understanding the\n","distribution, see the wikipedia page and of course the documentation in scipy.stats.beta.\n","\n","(a) Calculate the sample mean and sample standard deviation of X.\n","\n","(b) Reshape X using numpy into samples of size 25 each, and plot the histogram of the sample means.\n","\n","(c) Demonstrate the central limit theorem (CLT) using the sampling statistics and the histogram you just created above. Compare the statistics you get with those computed using the CLT. Do they match?\n","\n","(d) Now demonstrate how you can get a narrower distribution for the sample mean by changing the sample size and relate it to the sample standard deviation through\n","the CLT."],"metadata":{"id":"QaIgekt-pBBa"}},{"cell_type":"code","source":["a, b = 2, 5\n","X = stats.beta.rvs(a,b,size =5000,random_state=4)                              #Generates sample of size 5000 using beta distibution\n","\n","#a\n","sample_mean = X.mean()                                                          #calculates population mean\n","sam_s_d = X.std()                                                               #calculates population standard deviation\n","print(\"mean = \" ,sample_mean,\"Standard deviation = \",sam_s_d)\n","\n","#b\n","Reshaped_X = X.reshape(25, 200)                                                 #reshapes X into 200 samples of size 25 each\n","mean_Reshaped_X = (np.mean(Reshaped_X, axis=0))                                 \n","plt.figure(figsize = (10,10))\n","plt.hist(mean_Reshaped_X, color=\"Blue\")                                         #plots histogram of sample means\n","plt.show()\n","#c\n","Reshaped1_X = X.reshape(50, 100)                                                #reshapes X into 100 samples of size 50 each\n","mean_Reshaped1_X = (np.mean(Reshaped1_X, axis=0))\n","plt.figure(figsize = (10,10))\n","plt.hist(mean_Reshaped1_X, color=\"Black\")\n","plt.show()\n","mean = mean_Reshaped1_X.mean()\n","stdd = mean_Reshaped1_X.std()\n","print(\"Sample mean1 = \" ,mean,\"Sample Standard deviation1 = \",stdd)             #CLT is demonstrated as Sample mean for this case comes out be same as population mean and standard error decreases as sample size increases as seen in next case\n","\n","#d\n","Reshaped2_X = X.reshape(100, 50)                                                #reshapes X into 100 samples of size 50 each\n","mean_Reshaped2_X = (np.mean(Reshaped2_X, axis=0))\n","plt.figure(figsize = (10,10))\n","plt.hist(mean_Reshaped2_X, color=\"Brown\")\n","plt.show()\n","mean1 = mean_Reshaped2_X.mean()\n","stdd1 = mean_Reshaped2_X.std()\n","print(\"Sample mean2 = \" ,mean1,\"Sample Standard deviation2 = \",stdd1)           #Sample mean comes out be same as population mean, standard error decreases that is plot becomes narrower on increasing sample size from 25 to 50\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9hASqTepAUa","executionInfo":{"status":"ok","timestamp":1668745293918,"user_tz":-330,"elapsed":17,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"490bc161-9ada-4fea-be25-1704371e7a56"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["population mean= 0.2851878762085906 and popu;ation standard deviation= 0.15992451811133776\n"]}]},{"cell_type":"markdown","source":["I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena\n","\n","4th QUESTION\n","4. Descriptive statistics and hypothesis testing (10 marks)\n","Download the dataset called RainfallData.csv from the link at the top of the assigniment.The data you will focus on is the one corresponding to SUBDIVISION g-1 where g is your group number. For example, group 1 will work on SUBDIVISION[0]: Andaman & Nicobar Islands, and group 3 will work on SUBDIVISION[2]: Assam & Meghalaya. (g-1 because python is a 0 base language i.e, the first element in an array is the element 0.)\n","\n","(a) For your SUBDIVISION, do a scatter plot of the annual rainfall as a function of year.\n","\n","(b) Compute the sample mean, median, and sample standard deviation for annual\n","rainfall.\n","\n","(c) Plot a histogram and a horizontal boxplot one above the other (2x1 vector of\n","subplots) for annual rainfall.\n","\n","(d) How would you describe the distribution using the computed statistics and the plots above?\n","\n","(e) Pick two years and for these years, plot the monthly rainfall using a distinct symbol for the two different years. Add a legend for the years that you chose.\n","\n","(f) Compute the 95% confidence intervals for the mean annual rainfall in SUBDIVISION[g\u00021] and SUBDIVISION [g+1].\n","\n","(g) Are the mean annual rainfall values of these two SUBDIVISIONs distinct enough from each other? Why or why not? Hint: 2-sample hypothesis test.\n","\n","(h) Did you encounter missing values for some years in the SUBDIVISIONs you an\u0002alyzed? Explain how you handled these missing values.\n"],"metadata":{"id":"tYc5nwUW0Vpv"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import scipy.stats as beta\n","import scipy.stats as st\n","import random\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","rain=pd.read_csv('/content/drive/MyDrive/EN 207/RainfallData.csv')\n","rain['SUBDIVISION'].unique()\n","r=rain[rain['SUBDIVISION']=='Naga Mani Mizo Tripura']\n","plt.scatter(x='YEAR', y='ANNUAL',data=r,color='purple',linewidth=5)\n"],"metadata":{"id":"Z_15sn1hnqse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r['ANNUAL'].mean()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwJQuKP8x0LN","executionInfo":{"status":"ok","timestamp":1668703712571,"user_tz":-330,"elapsed":458,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"11683f7f-dee2-4457-d2cb-7c79f7038346"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2432.717948717949"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["r['ANNUAL'].median()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLhIyvDHx1JN","executionInfo":{"status":"ok","timestamp":1668703714542,"user_tz":-330,"elapsed":4,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"12e2ef91-d898-43a9-95cc-1d189967c8f5"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2423.0"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["r['ANNUAL'].std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrUb6rrCx4h7","executionInfo":{"status":"ok","timestamp":1668703716309,"user_tz":-330,"elapsed":4,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"f24425e7-7005-4438-e9fe-d1e1727f0cf4"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["431.6657562351927"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import seaborn as sns\n","fig1,axes2=plt.subplots(2,1)\n","sns.histplot(ax=axes2[0],data=r,x='ANNUAL',bins=25)\n","sns.boxplot(ax=axes2[1],data=r,x='ANNUAL')"],"metadata":{"id":"4k1DwBdjx8Uj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["d part\n","\n","''' Calculated mean=3403.9591397849463\n","Calculated median=3348.9\n","Calculated standard deviation=1071.8167875800334\n","We can describe the distribution as Normal distribution. We can observe from the histogram made, that the highest frequency is obtained close to the mean annual rainfall.\n","Also, generally these environmental data are normally distributed. '''"],"metadata":{"id":"qZUSOmBWBnJI"}},{"cell_type":"code","source":["r4=r.drop(['SUBDIVISION','ANNUAL','JF','MAM','JJAS','OND'],axis=1)\n","r1905=r4[(r4['YEAR']==1905) | (r4['YEAR']==1990)]\n","r1990=r4[r4['YEAR']==1990]\n","r1905=r1905.drop(['YEAR'],axis=1)\n","r1905=r1905.transpose()\n","r1905.columns=['1905','1990']\n","figs=plt.figure()\n","axi=figs.add_axes([0,0,1,1])\n","r1905.plot(kind='bar',ax=axi,stacked=False,fontsize=20)\n"],"metadata":{"id":"O3vfWmV7y3RH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#SUB DIVISION[3] Naga Mani Mizo Tripura and SUBDIVISION[5] Gangetic West Bengal\n","R=rain[rain['SUBDIVISION']=='Naga Mani Mizo Tripura']\n","RR=rain[rain['SUBDIVISION']=='Gangetic West Bengal']"],"metadata":{"id":"RgPDGQZ2BRsF","executionInfo":{"status":"ok","timestamp":1668703728197,"user_tz":-330,"elapsed":696,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["RR.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwjPvV3GFvcX","executionInfo":{"status":"ok","timestamp":1668703732904,"user_tz":-330,"elapsed":512,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"583e6924-238a-4f9c-f4f0-5b62f8858c2f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(117, 19)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import math\n","samp_mean_R= R['ANNUAL'].mean()\n","samp_std_R=R['ANNUAL'].std()\n","ml=samp_mean_R-(1.96*samp_std_R)/math.sqrt(117)\n","mr=samp_mean_R+(1.96*samp_std_R)/math.sqrt(117)\n","print(\"The mean range we get is : \", ml, \" to \",mr)\n","samp_mean_RR=RR['ANNUAL'].mean()\n","samp_std_RR=RR['ANNUAL'].std()\n","ml=samp_mean_RR-(1.96*samp_std_RR)/math.sqrt(117)\n","mr=samp_mean_RR+(1.96*samp_std_RR)/math.sqrt(117)\n","print(\"The mean range we get is : \", ml, \" to \",mr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3E5mZWCyFyq5","executionInfo":{"status":"ok","timestamp":1668703738024,"user_tz":-330,"elapsed":724,"user":{"displayName":"Manish H T","userId":"16615001296415148104"}},"outputId":"22e184c2-4e2a-454d-8131-86abddeb6dff"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean range we get is :  2354.4992226867407  to  2510.9366747491576\n","The mean range we get is :  1449.3540178314474  to  1531.871623194194\n"]}]},{"cell_type":"code","source":["#(g)\n","print(mean1)\n","print(mean2)\n","#Yes, the mean annual rainfall values of these two SUBDIVISIONs are distinct enough from each other. The reason is that the means are of different SUBDIVISIONs, that is they \n","#are of different geographical areas and these areas may recieve different amount of rainfall."],"metadata":{"id":"LejHfYGPCICs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["h part\n","\n","No I used isnull() fuction and it did not show up postive results for missing vlues in the dataset(Subdivision)"],"metadata":{"id":"cjoKg9XJCycw"}},{"cell_type":"markdown","source":["5. Fitting models to data I (10 marks)\n","You will work on the mtcars dataset to build simple linear regression models (one input and one output) as well as multiple linear regression models (several input variables and one output variable) for this problem. You may use the statsmodels.api module as demonstrated in heights sm.py - this script and heights lsqn.py are demos that show you how to fit simple linear models. Click the Google drive link given at the top of the assignment. These files are in the folder called linear-models. Download the mtcars dataset from the same link above. A good description of the columns in the dataset is given at the link below. https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\n","The output variable of main interest is the fuel consumption given in the column titled mpg.\n","\n","(a) Import the data into a pandas dataframe.\n","\n","(b) Create an additional column in the dataframe called kmpl and store the equivalent converted petrol consumption in units of km/litre in this column.\n","(c) Create additional columns in the dataframe called disp litres (displacement in litres), power kW (horsepower in kW), wt tons (mass in metric tons) and store\n","the equivalent/converted quantities given in columns disp, hp, and wt.\n","\n","(d) Fit a linear model giving kmpl as a function of disp litres. Plot the data and the model fit line. Report the fitted coefficients and their standard errors.\n","\n","(e) Is the fitted slope significant? Explain using your linear model output in python. Hint: learn how to use statsmodels.api as demonstrated in heights sm.py.\n","\n","(f) Fit a linear model giving kmpl as a function of disp litres and any other variables that you think should affect fuel consumption. Report the fitted coefficients and their standard errors.\n","\n","(g) Are all the fitted parameters significant? Explain using your linear model output in python.\n","\n","I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena\n"],"metadata":{"id":"NriGIq61pRvo"}},{"cell_type":"code","source":["#a\n","mtcars = pd.read_csv(\"/content/drive/MyDrive/EN 207/mtcars.csv\")\n","mtcars.head()\n","\n","#b\n","Km_Pl = pd.DataFrame([mtcars[\"mpg\"]*0.425])\n","New_Km_Pl = Km_Pl.T\n","mtcars[\"kmpl\"] = New_Km_Pl\n","mtcars.head(5)\n","\n","#c\n","D_L = pd.DataFrame([mtcars['disp']*0.0164]).T\n","power_kW = pd.DataFrame([mtcars['hp']*0.746]).T\n","wt_tons = pd.DataFrame([mtcars['wt']*0.454]).T\n","mtcars[\"disp_litres\"], mtcars[\"power_kW\"], mtcars[\"wt_tons\"] = [D_L, power_kW, wt_tons]\n","mtcars\n","\n","#d\n","y = mtcars['kmpl']\n","x = mtcars['disp_litres']\n","\n","import statsmodels.api as sm\n","x = sm.add_constant(x)\n","model_lin = sm.OLS(y,x).fit()\n","print(model_lin.summary())                                                      #  Equation of line : Km_Pl = 12.5799 - 1.0681 * (D_L) \n","                                                                                # fitted coefficients are:              1)-1.0681 (coefficient of D_L) and 2) 12.5799 (constant term)\n","                                                                                # Their corresponding standard errors : 1) 0.122                               and 2) 0.523\n","plt.plot(x,y,'ko')\n","plt.plot(x,model_lin.fittedvalues, 'b--',lw=2)\n","\n","#e\n","print( \"From the summary table: The P-value corresponding to both fitted coefficient is zero. P-value < 0.05 ==> The result is statistically significant\")\n","\n","#f\n","import pandas as pd\n","import statsmodels.formula.api as sm\n","model = sm.ols('kmpl ~ disp + power_kW + wt_tons', mtcars).fit()\n","print(model.params)\n","print(model.summary())\n","\n","#g\n","print(\"The P-values are:\")\n","\n","print(\"1) Intecept (0) which is less than 0.05 ==> Significant\")\n","\n","print(\"2) disp (0.929) which is greater than 0.05 ==> Not significant\")\n","\n","print(\"3) power_kW (0.011) which is less than 0.05 ==> Significant\")\n","\n","print(\"4) wt_tons (0.001) which is again less than 0.05 ==> Significant\")"],"metadata":{"id":"lPWRYGYZH0S0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H_1ILliB8x7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Question No-5      [This another way of doing it :) ]\n","#I have taken help from TAHA only\n","# (a)\n","# importing cars data in pandas data frame\n","K=pd.read_csv(\"/content/drive/MyDrive/EN 207/mtcars (1).csv\")\n","cars=pd.DataFrame(K)"],"metadata":{"id":"MuWRXvDPl3RI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (b)\n","# Calculating values for new column for KMPL\n","nd=cars['mpg']\n","nd=nd*0.425\n","cars['kmpl']=nd\n","cars"],"metadata":{"id":"u1T-GiRal7MP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (c)\n","# New columns for conversions of values to SI units\n","nd11=cars['disp']\n","nd11=nd11*0.0163871\n","cars['disp_litres']=nd11\n","nd12=cars['hp']\n","nd12=nd12*0.7457\n","cars['power_kW']=nd12\n","nd13=cars['wt']\n","nd13=nd13*453.592\n","cars['wt_tons']=nd13\n","cars"],"metadata":{"id":"SnDiZyngl-Gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (d)\n","# using Linear Regression for finding the best fit for the curve using the provide python library\n","import statsmodels.api as sm\n","y = cars.kmpl   # dependent variable\n","x = cars.disp_litres  # independent variable\n","o = np.ones(x.shape)    # vector of ones\n","X = np.column_stack((o, x))     # the X matrix \n","\n","model_lin = sm.OLS(y, X) # specifying linear model\n","results = model_lin.fit() # estimating parameters for the linear model\n","print(results.summary())  # print output of model fit\n","\n","xp = np.linspace(min(x), max(x), 21)\n","Xp = sm.add_constant(xp)\n","ci_pi = results.get_prediction(Xp).summary_frame(alpha=0.05)\n","\n","plt.plot(x, y, 'ko')\n","plt.plot(x, results.fittedvalues, 'b-', lw=2)\n","plt.plot(xp, ci_pi.obs_ci_lower, 'g--', lw=2)\n","plt.plot(xp, ci_pi.obs_ci_upper, 'g--', lw=2)\n","plt.plot(xp, ci_pi.mean_ci_lower, 'r--', lw=2)\n","plt.plot(xp, ci_pi.mean_ci_upper, 'r--', lw=2)\n","plt.xlabel('disp_litres')\n","plt.ylabel('kmpl')\n","plt.show()\n","cars.plot(kind=\"scatter\", x=\"disp_litres\", y=\"kmpl\")"],"metadata":{"id":"czhEnBZ8mCSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (f)\n","# using Linear Regression for finding the best fit for the curve using the provide python library\n","import statsmodels.api as sm\n","y = cars.kmpl   # dependent variable\n","x = cars.wt # independent variable\n","o = np.ones(x.shape)    # vector of ones\n","X = np.column_stack((o, x))     # the X matrix \n","\n","model_lin = sm.OLS(y, X) # specifying linear model\n","results = model_lin.fit() # estimating parameters for the linear model\n","print(results.summary())  # print output of model fit\n","\n","xp = np.linspace(min(x), max(x), 21)\n","Xp = sm.add_constant(xp)\n","ci_pi = results.get_prediction(Xp).summary_frame(alpha=0.05)\n","\n","plt.plot(x, y, 'ko')\n","plt.plot(x, results.fittedvalues, 'b-', lw=2)\n","plt.plot(xp, ci_pi.obs_ci_lower, 'g--', lw=2)\n","plt.plot(xp, ci_pi.obs_ci_upper, 'g--', lw=2)\n","plt.plot(xp, ci_pi.mean_ci_lower, 'r--', lw=2)\n","plt.plot(xp, ci_pi.mean_ci_upper, 'r--', lw=2)\n","plt.xlabel('disp_litres')\n","plt.ylabel('kmpl')\n","plt.show()\n","cars.plot(kind=\"scatter\", x=\"wt\", y=\"kmpl\")"],"metadata":{"id":"M2pw0aJkmHlF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Fitting models to data II (5 marks)\n","You will work on a dataset to build models where you need to linearize the model\n","before fitting it. The dataset your group will work on has your group number\n","at the end and is given in the folder called ReactionRate, link already given at the top.\n","The first column gives the temperature and the second gives the corresponding rate constant (you can ignore the third column if it exists). The rate constant is expected to obey the Arrhenius equation which is usually parameterized by a pre-exponential constant A and an activation energy E.\n","\n","(a) Import the data assigned to your team into a pandas dataframe.\n","\n","(b) Your second task is to transform the data into a form which allows you to fit a linear equation and store the transformed variables in new columns as required.\n","\n","(c) Now fit a linear model that describes the transformed k as a function of trans\u0002formed T. Plot the data and the model fit line. Report the fitted coefficients and their standard errors.\n","\n","(d) Do a reverse transform to give you the estimated parameters for the Arrhenius equation.\n","\n","(e) Can you compute the 95% confidence intervals for the pre-exponential constant A and the activation energy E? If so, please compute and report these CIs. If not, report any related quantities that you can compute.\n","\n","I have taken help from my group members and my classmates Names : Sarthak Sonkar,Sanket Maskhe,Taha S K, Samyak Maurya, Prateek Mishra\n","I have helped the above named people and as well as Harshit Meena"],"metadata":{"id":"2j2brtWwrWRr"}},{"cell_type":"code","source":["#a\n","RR = pd.read_csv(\"/content/drive/MyDrive/EN 207/CNH2ReactionRate4.csv\")"],"metadata":{"id":"taeOi3o1rVbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#b\n","RR['logk']=np.log(RR['k (in cm3 per mol per sec)'])\n","RR['1/T']=1/RR['T (in K)']"],"metadata":{"id":"YvUBTU3jr04X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#c\n","import statsmodels.formula.api as sm\n","y=RR['logk']\n","x=RR['1/T']\n","one= np.ones(x.shape)\n","X= np.column_stack((x,one))\n","import statsmodels.api as sm\n","arr_model= sm.OLS(y,x)\n","results= arr_model.fit()\n","print(results.summary())\n","results.fittedvalues"],"metadata":{"id":"JCtdVl_or6Qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#d\n","A = 2.71828182892*7.3159\n","Ea = -2103.9631*8.31447\n","print(\"The value of the pre exponential factor is =\", A, \"cm3/mol.sec\")\n","print(\"The value of the activation energy is=\", Ea, \"J/mol\")"],"metadata":{"id":"8V4SXVoAr-f0"},"execution_count":null,"outputs":[]}]}
